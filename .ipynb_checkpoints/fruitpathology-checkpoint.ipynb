{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ttach in /home/dongbin/anaconda3/envs/db_pytorch/lib/python3.6/site-packages (0.0.2)\r\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.utils import model_zoo\n",
    "import re\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import model_zoo\n",
    "import torch.utils.data as Data\n",
    "from pathlib import Path\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from albumentations.pytorch import ToTensor\n",
    "import os.path as osp\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import albumentations as albu\n",
    "import pretrainedmodels as models\n",
    "import ttach as tta\n",
    "from scipy.special import softmax\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '5'\n",
    "\n",
    "!pip install ttach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = '/data/Dataset/plant-pathology-2020-fgvc7/images/'\n",
    "\n",
    "def get_image_path(filename):\n",
    "    return (IMAGE_FOLDER + filename + '.jpg')\n",
    "\n",
    "test = pd.read_csv('/data/Dataset/plant-pathology-2020-fgvc7/test.csv')\n",
    "test['image_path'] = test['image_id'].apply(get_image_path)\n",
    "test_paths = test.image_path\n",
    "\n",
    "class LeafPILDataset(Data.Dataset):\n",
    "    def __init__(self, image_paths, labels=None, train=True, test=False, aug=None):\n",
    "        self.paths = image_paths\n",
    "        self.test = test\n",
    "        if self.test == False:\n",
    "            self.labels = labels\n",
    "        self.train = train\n",
    "        self.transform = albu.Compose([albu.HorizontalFlip(p=0.5),\n",
    "                                  albu.VerticalFlip(p=0.5),\n",
    "                                  albu.ShiftScaleRotate(rotate_limit=25.0, p=0.7),\n",
    "                                  albu.OneOf([albu.IAAEmboss(p=1),\n",
    "                                         albu.IAASharpen(p=1),\n",
    "                                         albu.Blur(p=1)], p=0.5),\n",
    "                                  albu.IAAPiecewiseAffine(p=0.5),\n",
    "                                  albu.Resize(545, 545, always_apply=True),\n",
    "                                  albu.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                                  ToTensor(),\n",
    "                                  ])\n",
    "\n",
    "        self.default_transform = albu.Compose([albu.Resize(545, 545, always_apply=True),\n",
    "                                          albu.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225), always_apply=True),\n",
    "                                          ToTensor()])  # normalized for pretrained network\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.paths.shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        image = self.load_image(self.paths[i])\n",
    "        if self.test == False:\n",
    "            label = torch.tensor(np.argmax(self.labels.loc[i,:].values))  # loss function used later doesnt take one-hot encoded labels, so convert it using argmax\n",
    "        if self.train:\n",
    "            image = self.transform(image=image)['image']\n",
    "        else:\n",
    "            image = self.default_transform(image=image)['image']\n",
    "\n",
    "        if self.test == False:\n",
    "            return image, label\n",
    "        return image\n",
    "\n",
    "    def load_image(self, path):\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgPool(nn.Module):\n",
    "        def forward(self, x):\n",
    "            return F.avg_pool2d(x, x.shape[2:])\n",
    "\n",
    "def load_model(model, path):\n",
    "    state = torch.load(str(path))\n",
    "    model.load_state_dict(state) # repo1\n",
    "    return state\n",
    "\n",
    "def create_model(model_name,model,model_path):\n",
    "    N_CLASSES = 4\n",
    "    feature_dim = model.last_linear.in_features \n",
    "    \n",
    "    model.avg_pool = AvgPool()\n",
    "    model.avgpool = AvgPool()\n",
    "    model.last_linear = nn.Linear(feature_dim, N_CLASSES)  \n",
    "    \n",
    "    state = torch.load(str(model_path))\n",
    "    model.load_state_dict(state) \n",
    "    model = model.cuda()\n",
    "    return model\n",
    "\n",
    "model_name = 'pnasnet5large'\n",
    "model = getattr(models, model_name)(pretrained=None)\n",
    "\n",
    "# you can get our model weights from here: \n",
    "# https://drive.google.com/file/d/1Tn7GNlbNOjJaGwPTqDXGb5iqhFgOY1ZF/view?usp=sharing\n",
    "model_dir = './pl_ckpts/model_pnasnet5large_albu_re_pseudo95'\n",
    "model = create_model(model_name,model,Path(os.path.join(model_dir,'best-model.pt')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 228/228 [00:44<00:00,  5.09it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = LeafPILDataset(test_paths, train=False, test=True)\n",
    "testloader = Data.DataLoader(test_dataset, shuffle=False, batch_size=8, num_workers=2)\n",
    "\n",
    "is_tta = False\n",
    "def test_fn(net, loader, is_tta=False):\n",
    "    if is_tta:\n",
    "        print('=> using tta inference.')\n",
    "        transforms = tta.Compose(\n",
    "                [\n",
    "                    tta.Scale(scales=[1]), # self\n",
    "                    tta.HorizontalFlip(),\n",
    "                    tta.FiveCrops(545,545) # abulation\n",
    "                ]\n",
    "            )\n",
    "        net = tta.ClassificationTTAWrapper(net, transforms, merge_mode='mean')\n",
    "\n",
    "    net.eval()\n",
    "    preds_for_output = np.zeros((1,4))\n",
    "    device = 'cuda'\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(total = len(loader))\n",
    "        for _, images in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            predictions = net(images)\n",
    "            preds_for_output = np.concatenate((preds_for_output, predictions.cpu().detach().numpy()), 0)\n",
    "            pbar.update()\n",
    "    \n",
    "    pbar.close()\n",
    "    return preds_for_output\n",
    "out = test_fn(model, testloader, is_tta=is_tta)\n",
    "\n",
    "output = pd.DataFrame(softmax(out,1), columns = ['healthy','multiple_diseases','rust','scab']) # the submission expects probability scores for each class\n",
    "output.drop(0, inplace = True)\n",
    "output.reset_index(drop=True,inplace=True)\n",
    "output['image_id'] = test.image_id\n",
    "output = output[['image_id','healthy','multiple_diseases','rust','scab']]\n",
    "\n",
    "output.to_csv(os.path.join(model_dir,'tta_submission.csv' if is_tta else 'submission.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "db_pytorch",
   "language": "python",
   "name": "db_pytorcch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
